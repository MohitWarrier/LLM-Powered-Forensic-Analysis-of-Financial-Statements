{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Optimization Research Notebook\n",
    "\n",
    "**Project:** Finance Software Suite  \n",
    "**Module:** Portfolio Optimization  \n",
    "**Purpose:** Compare Mean-Variance, Min-Variance, Equal-Weight, and Risk-Parity strategies  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "1. [Setup & Data](#1-setup--data)\n",
    "2. [Returns Analysis](#2-returns-analysis)\n",
    "3. [Mean-Variance Optimization (Markowitz)](#3-mean-variance-optimization-markowitz)\n",
    "4. [Risk Metrics](#4-risk-metrics)\n",
    "5. [Equal Weight Portfolio (Baseline)](#5-equal-weight-portfolio-baseline)\n",
    "6. [Risk Parity](#6-risk-parity)\n",
    "7. [Strategy Comparison](#7-strategy-comparison)\n",
    "8. [Next Steps / Extension Points](#8-next-steps--extension-points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Data\n",
    "\n",
    "Install dependencies (safe to re-run on Colab) and generate synthetic price data\n",
    "that matches the project's `DummyDataProvider`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab / pip install cell ---\n",
    "# Run this cell first on Google Colab. It is safe to re-run locally.\n",
    "import subprocess, sys\n",
    "\n",
    "_REQUIRED = [\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"scipy\",\n",
    "    \"plotly\",\n",
    "    \"matplotlib\",\n",
    "]\n",
    "\n",
    "for pkg in _REQUIRED:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "print(\"All dependencies available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: add project src/ to path so we can import local modules ---\n",
    "# This block is a no-op on Colab (the path simply won't exist).\n",
    "import os, sys, pathlib\n",
    "\n",
    "_PROJECT_ROOT = pathlib.Path(os.getcwd()).parent  # notebooks/ -> project root\n",
    "if (_PROJECT_ROOT / \"src\").exists():\n",
    "    sys.path.insert(0, str(_PROJECT_ROOT))\n",
    "    print(f\"Project root added to sys.path: {_PROJECT_ROOT}\")\n",
    "else:\n",
    "    print(\"Running standalone (project src/ not found). All logic is inlined below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core imports ---\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats as sp_stats\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "\n",
    "# Constants used throughout the notebook\n",
    "RISK_FREE_RATE = 0.02        # 2 % annual risk-free rate\n",
    "TRADING_DAYS   = 252         # annualization factor\n",
    "NUM_PORTFOLIOS = 10_000      # Monte Carlo simulations\n",
    "\n",
    "print(f\"numpy {np.__version__}, pandas {pd.__version__}\")\n",
    "print(f\"Risk-free rate: {RISK_FREE_RATE:.0%}, Trading days: {TRADING_DAYS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate synthetic price data ---\n",
    "# Mirrors src/data/dummy_provider.py -> DummyDataProvider.get_portfolio_data()\n",
    "\n",
    "np.random.seed(42)  # reset seed for reproducible data\n",
    "\n",
    "dates   = pd.bdate_range(start=\"2022-01-03\", end=\"2023-12-29\")\n",
    "tickers = [\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"TSLA\"]\n",
    "\n",
    "# Annualized parameters per asset\n",
    "annual_returns = [0.12, 0.10, 0.14, 0.08, 0.20]\n",
    "annual_vols    = [0.25, 0.22, 0.20, 0.28, 0.45]\n",
    "\n",
    "prices = pd.DataFrame(index=dates, columns=tickers, dtype=float)\n",
    "for i, ticker in enumerate(tickers):\n",
    "    daily_ret = annual_returns[i] / TRADING_DAYS\n",
    "    daily_vol = annual_vols[i] / np.sqrt(TRADING_DAYS)\n",
    "    log_returns = np.random.normal(daily_ret, daily_vol, len(dates))\n",
    "    prices[ticker] = 100.0 * np.cumprod(1 + log_returns)\n",
    "\n",
    "n_days   = len(prices)\n",
    "n_assets = len(tickers)\n",
    "\n",
    "print(f\"Generated {n_days} business days of price data for {n_assets} assets\")\n",
    "print(f\"Date range: {prices.index[0].date()} to {prices.index[-1].date()}\")\n",
    "prices.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Price chart ---\n",
    "fig = go.Figure()\n",
    "for col in prices.columns:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=prices.index, y=prices[col],\n",
    "        mode=\"lines\", name=col,\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Synthetic Asset Prices (Base = 100)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Price ($)\",\n",
    "    height=500,\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Returns Analysis\n",
    "\n",
    "Compute daily log returns and explore their statistical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Daily simple returns ---\n",
    "daily_returns = prices.pct_change().dropna()\n",
    "\n",
    "print(f\"Daily returns shape: {daily_returns.shape}\")\n",
    "daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Return distribution histograms (matplotlib) ---\n",
    "fig, axes = plt.subplots(1, n_assets, figsize=(18, 4), sharey=True)\n",
    "\n",
    "for ax, ticker in zip(axes, tickers):\n",
    "    data = daily_returns[ticker]\n",
    "    ax.hist(data, bins=50, edgecolor=\"white\", alpha=0.8, color=\"steelblue\")\n",
    "    ax.axvline(data.mean(), color=\"red\", linewidth=1.2, linestyle=\"--\", label=\"Mean\")\n",
    "    ax.set_title(ticker, fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Daily Return\")\n",
    "    ax.xaxis.set_major_formatter(mticker.PercentFormatter(xmax=1, decimals=0))\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "fig.suptitle(\"Daily Return Distributions\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summary statistics table ---\n",
    "summary = pd.DataFrame({\n",
    "    \"Ann. Mean Return\": daily_returns.mean() * TRADING_DAYS,\n",
    "    \"Ann. Volatility\":  daily_returns.std() * np.sqrt(TRADING_DAYS),\n",
    "    \"Skewness\":         daily_returns.skew(),\n",
    "    \"Excess Kurtosis\":  daily_returns.kurtosis(),\n",
    "    \"Min Daily\":        daily_returns.min(),\n",
    "    \"Max Daily\":        daily_returns.max(),\n",
    "})\n",
    "\n",
    "# Format for display\n",
    "summary_display = summary.copy()\n",
    "summary_display[\"Ann. Mean Return\"]  = summary_display[\"Ann. Mean Return\"].apply(lambda x: f\"{x:.2%}\")\n",
    "summary_display[\"Ann. Volatility\"]   = summary_display[\"Ann. Volatility\"].apply(lambda x: f\"{x:.2%}\")\n",
    "summary_display[\"Min Daily\"]         = summary_display[\"Min Daily\"].apply(lambda x: f\"{x:.2%}\")\n",
    "summary_display[\"Max Daily\"]         = summary_display[\"Max Daily\"].apply(lambda x: f\"{x:.2%}\")\n",
    "\n",
    "print(\"Return Summary Statistics\")\n",
    "print(\"=\" * 80)\n",
    "summary_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Correlation matrix heatmap ---\n",
    "corr_matrix = daily_returns.corr()\n",
    "\n",
    "fig = px.imshow(\n",
    "    corr_matrix,\n",
    "    text_auto=\".2f\",\n",
    "    color_continuous_scale=\"RdBu_r\",\n",
    "    zmin=-1, zmax=1,\n",
    "    aspect=\"auto\",\n",
    "    title=\"Asset Return Correlation Matrix\",\n",
    ")\n",
    "fig.update_layout(height=450, template=\"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Mean-Variance Optimization (Markowitz)\n",
    "\n",
    "The classical Markowitz framework finds portfolio weights that maximize\n",
    "risk-adjusted return (Sharpe ratio) or minimize variance.\n",
    "\n",
    "**Steps:**\n",
    "1. Estimate expected returns and the covariance matrix from historical data.\n",
    "2. Run a Monte Carlo simulation of 10,000 random portfolios to visualize the opportunity set.\n",
    "3. Use `scipy.optimize.minimize` to find the max-Sharpe and min-variance portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Expected returns and covariance ---\n",
    "mean_returns = daily_returns.mean() * TRADING_DAYS\n",
    "cov_matrix   = daily_returns.cov()  * TRADING_DAYS\n",
    "\n",
    "print(\"Annualized Expected Returns\")\n",
    "for t, r in mean_returns.items():\n",
    "    print(f\"  {t}: {r:>8.2%}\")\n",
    "\n",
    "print(\"\\nAnnualized Covariance Matrix\")\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Monte Carlo simulation: 10,000 random portfolios ---\n",
    "np.random.seed(42)\n",
    "\n",
    "mc_returns   = np.zeros(NUM_PORTFOLIOS)\n",
    "mc_vols      = np.zeros(NUM_PORTFOLIOS)\n",
    "mc_sharpes   = np.zeros(NUM_PORTFOLIOS)\n",
    "mc_weights   = np.zeros((NUM_PORTFOLIOS, n_assets))\n",
    "\n",
    "cov_values = cov_matrix.values\n",
    "\n",
    "for i in range(NUM_PORTFOLIOS):\n",
    "    w = np.random.dirichlet(np.ones(n_assets))\n",
    "    mc_weights[i] = w\n",
    "    ret = np.dot(w, mean_returns.values)\n",
    "    vol = np.sqrt(np.dot(w.T, np.dot(cov_values, w)))\n",
    "    mc_returns[i] = ret\n",
    "    mc_vols[i]    = vol\n",
    "    mc_sharpes[i] = (ret - RISK_FREE_RATE) / vol if vol > 0 else 0.0\n",
    "\n",
    "print(f\"Simulated {NUM_PORTFOLIOS:,} random portfolios\")\n",
    "print(f\"Sharpe range: [{mc_sharpes.min():.2f}, {mc_sharpes.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimize for Maximum Sharpe Ratio ---\n",
    "def neg_sharpe(w, mean_ret, cov_mat, rf):\n",
    "    \"\"\"Negative Sharpe ratio (minimize to find max Sharpe).\"\"\"\n",
    "    port_ret = np.dot(w, mean_ret)\n",
    "    port_vol = np.sqrt(np.dot(w.T, np.dot(cov_mat, w)))\n",
    "    return -(port_ret - rf) / port_vol if port_vol > 0 else 0\n",
    "\n",
    "constraints = [{\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0}]\n",
    "bounds      = tuple((0.0, 1.0) for _ in range(n_assets))\n",
    "w0          = np.array([1.0 / n_assets] * n_assets)\n",
    "\n",
    "opt_sharpe_result = minimize(\n",
    "    neg_sharpe, w0, args=(mean_returns.values, cov_values, RISK_FREE_RATE),\n",
    "    method=\"SLSQP\", bounds=bounds, constraints=constraints,\n",
    ")\n",
    "\n",
    "w_max_sharpe   = opt_sharpe_result.x\n",
    "ret_max_sharpe = float(np.dot(w_max_sharpe, mean_returns.values))\n",
    "vol_max_sharpe = float(np.sqrt(np.dot(w_max_sharpe.T, np.dot(cov_values, w_max_sharpe))))\n",
    "sr_max_sharpe  = (ret_max_sharpe - RISK_FREE_RATE) / vol_max_sharpe\n",
    "\n",
    "print(\"=== Max Sharpe Portfolio ===\")\n",
    "print(f\"  Expected Return: {ret_max_sharpe:.2%}\")\n",
    "print(f\"  Volatility:      {vol_max_sharpe:.2%}\")\n",
    "print(f\"  Sharpe Ratio:    {sr_max_sharpe:.4f}\")\n",
    "print(f\"  Weights:\")\n",
    "for t, wt in zip(tickers, w_max_sharpe):\n",
    "    print(f\"    {t}: {wt:.4f} ({wt:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimize for Minimum Variance ---\n",
    "def portfolio_variance(w, cov_mat):\n",
    "    \"\"\"Portfolio variance.\"\"\"\n",
    "    return np.dot(w.T, np.dot(cov_mat, w))\n",
    "\n",
    "opt_minvar_result = minimize(\n",
    "    portfolio_variance, w0, args=(cov_values,),\n",
    "    method=\"SLSQP\", bounds=bounds, constraints=constraints,\n",
    ")\n",
    "\n",
    "w_min_var   = opt_minvar_result.x\n",
    "ret_min_var = float(np.dot(w_min_var, mean_returns.values))\n",
    "vol_min_var = float(np.sqrt(np.dot(w_min_var.T, np.dot(cov_values, w_min_var))))\n",
    "sr_min_var  = (ret_min_var - RISK_FREE_RATE) / vol_min_var\n",
    "\n",
    "print(\"=== Minimum Variance Portfolio ===\")\n",
    "print(f\"  Expected Return: {ret_min_var:.2%}\")\n",
    "print(f\"  Volatility:      {vol_min_var:.2%}\")\n",
    "print(f\"  Sharpe Ratio:    {sr_min_var:.4f}\")\n",
    "print(f\"  Weights:\")\n",
    "for t, wt in zip(tickers, w_min_var):\n",
    "    print(f\"    {t}: {wt:.4f} ({wt:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Efficient Frontier scatter plot ---\n",
    "fig = go.Figure()\n",
    "\n",
    "# Simulated portfolios (colored by Sharpe)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=mc_vols, y=mc_returns, mode=\"markers\",\n",
    "    marker=dict(\n",
    "        color=mc_sharpes, colorscale=\"Viridis\", showscale=True,\n",
    "        colorbar=dict(title=\"Sharpe Ratio\"),\n",
    "        size=3, opacity=0.5,\n",
    "    ),\n",
    "    text=[f\"Sharpe: {s:.2f}\" for s in mc_sharpes],\n",
    "    name=\"Simulated (n=10,000)\",\n",
    "))\n",
    "\n",
    "# Max Sharpe\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[vol_max_sharpe], y=[ret_max_sharpe], mode=\"markers\",\n",
    "    marker=dict(color=\"red\", size=16, symbol=\"star\", line=dict(width=1, color=\"black\")),\n",
    "    name=f\"Max Sharpe ({sr_max_sharpe:.2f})\",\n",
    "))\n",
    "\n",
    "# Min Variance\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[vol_min_var], y=[ret_min_var], mode=\"markers\",\n",
    "    marker=dict(color=\"blue\", size=14, symbol=\"diamond\", line=dict(width=1, color=\"black\")),\n",
    "    name=f\"Min Variance ({sr_min_var:.2f})\",\n",
    "))\n",
    "\n",
    "# Individual assets\n",
    "individual_vols = [float(np.sqrt(cov_matrix.loc[t, t])) for t in tickers]\n",
    "individual_rets = [float(mean_returns[t]) for t in tickers]\n",
    "for t, iv, ir in zip(tickers, individual_vols, individual_rets):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[iv], y=[ir], mode=\"markers+text\",\n",
    "        marker=dict(color=\"orange\", size=10, symbol=\"circle\"),\n",
    "        text=[t], textposition=\"top center\",\n",
    "        name=t, showlegend=False,\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Efficient Frontier (Monte Carlo + Optimized Portfolios)\",\n",
    "    xaxis_title=\"Annualized Volatility\",\n",
    "    yaxis_title=\"Annualized Expected Return\",\n",
    "    xaxis_tickformat=\".0%\",\n",
    "    yaxis_tickformat=\".0%\",\n",
    "    height=600,\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimal weights bar chart ---\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\"Max Sharpe Weights\", \"Min Variance Weights\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=tickers, y=w_max_sharpe,\n",
    "    text=[f\"{w:.1%}\" for w in w_max_sharpe],\n",
    "    textposition=\"auto\", marker_color=\"indianred\",\n",
    "    name=\"Max Sharpe\",\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=tickers, y=w_min_var,\n",
    "    text=[f\"{w:.1%}\" for w in w_min_var],\n",
    "    textposition=\"auto\", marker_color=\"steelblue\",\n",
    "    name=\"Min Variance\",\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.update_yaxes(tickformat=\".0%\", title_text=\"Weight\", row=1, col=1)\n",
    "fig.update_yaxes(tickformat=\".0%\", row=1, col=2)\n",
    "fig.update_layout(height=400, template=\"plotly_white\", showlegend=False,\n",
    "                  title_text=\"Portfolio Weight Comparison\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Risk Metrics\n",
    "\n",
    "Compute comprehensive risk metrics for the **Max Sharpe** portfolio:\n",
    "- Value at Risk (parametric and historical)\n",
    "- Conditional VaR / Expected Shortfall\n",
    "- Maximum Drawdown\n",
    "- Sortino Ratio\n",
    "- Calmar Ratio\n",
    "- Rolling volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Portfolio daily returns (max Sharpe weights) ---\n",
    "port_daily_returns = daily_returns.dot(w_max_sharpe)\n",
    "port_daily_returns.name = \"Max Sharpe Portfolio\"\n",
    "\n",
    "ann_port_ret = port_daily_returns.mean() * TRADING_DAYS\n",
    "ann_port_vol = port_daily_returns.std()  * np.sqrt(TRADING_DAYS)\n",
    "\n",
    "print(f\"Portfolio daily returns: {len(port_daily_returns)} observations\")\n",
    "print(f\"Annualized return: {ann_port_ret:.2%}\")\n",
    "print(f\"Annualized vol:    {ann_port_vol:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Value at Risk ---\n",
    "\n",
    "# Parametric VaR (assumes normal distribution)\n",
    "mu_daily  = port_daily_returns.mean()\n",
    "std_daily = port_daily_returns.std()\n",
    "\n",
    "var_95_parametric = mu_daily + sp_stats.norm.ppf(0.05) * std_daily\n",
    "var_99_parametric = mu_daily + sp_stats.norm.ppf(0.01) * std_daily\n",
    "\n",
    "# Historical VaR (empirical quantile)\n",
    "var_95_historical = float(np.percentile(port_daily_returns, 5))\n",
    "var_99_historical = float(np.percentile(port_daily_returns, 1))\n",
    "\n",
    "print(\"=== Value at Risk (daily) ===\")\n",
    "print(f\"  Parametric VaR 95%: {var_95_parametric:.4%}\")\n",
    "print(f\"  Parametric VaR 99%: {var_99_parametric:.4%}\")\n",
    "print(f\"  Historical VaR 95%: {var_95_historical:.4%}\")\n",
    "print(f\"  Historical VaR 99%: {var_99_historical:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Conditional VaR (Expected Shortfall) ---\n",
    "# Average loss beyond VaR threshold\n",
    "\n",
    "cvar_95 = float(port_daily_returns[port_daily_returns <= var_95_historical].mean())\n",
    "cvar_99 = float(port_daily_returns[port_daily_returns <= var_99_historical].mean())\n",
    "\n",
    "print(\"=== Conditional VaR / Expected Shortfall (daily) ===\")\n",
    "print(f\"  CVaR 95%: {cvar_95:.4%}\")\n",
    "print(f\"  CVaR 99%: {cvar_99:.4%}\")\n",
    "print(f\"\")\n",
    "print(f\"  Interpretation: On the worst 5% of days, the portfolio loses\")\n",
    "print(f\"  {abs(cvar_95):.2%} on average.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Maximum Drawdown ---\n",
    "cumulative     = (1 + port_daily_returns).cumprod()\n",
    "rolling_max    = cumulative.cummax()\n",
    "drawdown       = (cumulative - rolling_max) / rolling_max\n",
    "max_drawdown   = float(drawdown.min())\n",
    "max_dd_date    = drawdown.idxmin()\n",
    "\n",
    "print(f\"Maximum Drawdown: {max_drawdown:.2%}\")\n",
    "print(f\"Occurred on:      {max_dd_date.date()}\")\n",
    "\n",
    "# Drawdown plot\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1, shared_xaxes=True,\n",
    "    subplot_titles=(\"Cumulative Return\", \"Drawdown\"),\n",
    "    vertical_spacing=0.08,\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=cumulative.index, y=cumulative.values,\n",
    "    mode=\"lines\", name=\"Cumulative Return\",\n",
    "    line=dict(color=\"steelblue\"),\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=drawdown.index, y=drawdown.values,\n",
    "    mode=\"lines\", name=\"Drawdown\",\n",
    "    fill=\"tozeroy\", line=dict(color=\"indianred\"),\n",
    "), row=2, col=1)\n",
    "\n",
    "fig.add_hline(y=max_drawdown, line_dash=\"dash\", line_color=\"black\",\n",
    "              annotation_text=f\"Max DD: {max_drawdown:.1%}\", row=2, col=1)\n",
    "\n",
    "fig.update_yaxes(tickformat=\".0%\", row=2, col=1)\n",
    "fig.update_layout(height=600, template=\"plotly_white\",\n",
    "                  title_text=\"Max Sharpe Portfolio: Cumulative Return & Drawdown\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sortino Ratio ---\n",
    "# Uses downside deviation (only negative returns) instead of total std\n",
    "\n",
    "downside_returns = port_daily_returns[port_daily_returns < 0]\n",
    "downside_std     = float(downside_returns.std() * np.sqrt(TRADING_DAYS))\n",
    "sortino_ratio    = (ann_port_ret - RISK_FREE_RATE) / downside_std if downside_std > 0 else 0\n",
    "\n",
    "print(f\"Sortino Ratio: {sortino_ratio:.4f}\")\n",
    "print(f\"  (Sharpe uses total vol = {ann_port_vol:.2%}, \"\n",
    "      f\"Sortino uses downside vol = {downside_std:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calmar Ratio ---\n",
    "# Annualized return / |max drawdown|\n",
    "\n",
    "calmar_ratio = ann_port_ret / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "\n",
    "print(f\"Calmar Ratio: {calmar_ratio:.4f}\")\n",
    "print(f\"  (Ann. Return = {ann_port_ret:.2%}, Max DD = {max_drawdown:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rolling volatility (30-day window) ---\n",
    "rolling_vol = port_daily_returns.rolling(window=30).std() * np.sqrt(TRADING_DAYS)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=rolling_vol.index, y=rolling_vol.values,\n",
    "    mode=\"lines\", name=\"30-Day Rolling Vol\",\n",
    "    line=dict(color=\"steelblue\"),\n",
    "))\n",
    "fig.add_hline(y=ann_port_vol, line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=f\"Full-period vol: {ann_port_vol:.1%}\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Max Sharpe Portfolio: 30-Day Rolling Annualized Volatility\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Annualized Volatility\",\n",
    "    yaxis_tickformat=\".0%\",\n",
    "    height=400,\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Risk metrics summary table ---\n",
    "risk_summary = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Parametric VaR 95% (daily)\",\n",
    "        \"Parametric VaR 99% (daily)\",\n",
    "        \"Historical VaR 95% (daily)\",\n",
    "        \"Historical VaR 99% (daily)\",\n",
    "        \"CVaR / Expected Shortfall 95%\",\n",
    "        \"CVaR / Expected Shortfall 99%\",\n",
    "        \"Maximum Drawdown\",\n",
    "        \"Sharpe Ratio\",\n",
    "        \"Sortino Ratio\",\n",
    "        \"Calmar Ratio\",\n",
    "        \"Skewness\",\n",
    "        \"Excess Kurtosis\",\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{var_95_parametric:.4%}\",\n",
    "        f\"{var_99_parametric:.4%}\",\n",
    "        f\"{var_95_historical:.4%}\",\n",
    "        f\"{var_99_historical:.4%}\",\n",
    "        f\"{cvar_95:.4%}\",\n",
    "        f\"{cvar_99:.4%}\",\n",
    "        f\"{max_drawdown:.2%}\",\n",
    "        f\"{sr_max_sharpe:.4f}\",\n",
    "        f\"{sortino_ratio:.4f}\",\n",
    "        f\"{calmar_ratio:.4f}\",\n",
    "        f\"{port_daily_returns.skew():.4f}\",\n",
    "        f\"{port_daily_returns.kurtosis():.4f}\",\n",
    "    ],\n",
    "})\n",
    "risk_summary.set_index(\"Metric\", inplace=True)\n",
    "risk_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Equal Weight Portfolio (Baseline)\n",
    "\n",
    "A naive 1/N allocation serves as a strong baseline.  \n",
    "Research (DeMiguel, Garlappi, Uppal, 2009) shows that equal-weight often\n",
    "outperforms optimized portfolios out-of-sample due to estimation error in\n",
    "expected returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Equal weight portfolio ---\n",
    "w_equal = np.array([1.0 / n_assets] * n_assets)\n",
    "\n",
    "ret_equal = float(np.dot(w_equal, mean_returns.values))\n",
    "vol_equal = float(np.sqrt(np.dot(w_equal.T, np.dot(cov_values, w_equal))))\n",
    "sr_equal  = (ret_equal - RISK_FREE_RATE) / vol_equal\n",
    "\n",
    "# Daily returns for this portfolio\n",
    "port_equal_returns = daily_returns.dot(w_equal)\n",
    "\n",
    "# Downside metrics\n",
    "ds_equal     = port_equal_returns[port_equal_returns < 0]\n",
    "ds_std_equal = float(ds_equal.std() * np.sqrt(TRADING_DAYS)) if len(ds_equal) > 0 else 0\n",
    "sortino_equal = (ret_equal - RISK_FREE_RATE) / ds_std_equal if ds_std_equal > 0 else 0\n",
    "\n",
    "# Max drawdown\n",
    "cum_equal    = (1 + port_equal_returns).cumprod()\n",
    "dd_equal     = (cum_equal - cum_equal.cummax()) / cum_equal.cummax()\n",
    "max_dd_equal = float(dd_equal.min())\n",
    "calmar_equal = ret_equal / abs(max_dd_equal) if max_dd_equal != 0 else 0\n",
    "\n",
    "print(\"=== Equal Weight (1/N) Portfolio ===\")\n",
    "print(f\"  Weights:         {dict(zip(tickers, w_equal.round(4)))}\")\n",
    "print(f\"  Expected Return: {ret_equal:.2%}\")\n",
    "print(f\"  Volatility:      {vol_equal:.2%}\")\n",
    "print(f\"  Sharpe Ratio:    {sr_equal:.4f}\")\n",
    "print(f\"  Sortino Ratio:   {sortino_equal:.4f}\")\n",
    "print(f\"  Max Drawdown:    {max_dd_equal:.2%}\")\n",
    "print(f\"  Calmar Ratio:    {calmar_equal:.4f}\")\n",
    "print()\n",
    "print(\"--- vs Max Sharpe ---\")\n",
    "print(f\"  Return diff:  {ret_max_sharpe - ret_equal:+.2%}\")\n",
    "print(f\"  Vol diff:     {vol_max_sharpe - vol_equal:+.2%}\")\n",
    "print(f\"  Sharpe diff:  {sr_max_sharpe - sr_equal:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Risk Parity\n",
    "\n",
    "### Concept\n",
    "\n",
    "**Risk Parity** allocates weights so that each asset contributes *equally*\n",
    "to the total portfolio risk (volatility).  Unlike mean-variance optimization,\n",
    "it does **not** use expected returns as inputs, making it more robust to\n",
    "estimation error.\n",
    "\n",
    "**Risk contribution** of asset $i$:\n",
    "\n",
    "$$RC_i = w_i \\cdot \\frac{(\\Sigma w)_i}{\\sqrt{w^T \\Sigma w}}$$\n",
    "\n",
    "The optimization objective is:\n",
    "\n",
    "$$\\min_w \\sum_{i=1}^{N} \\left( RC_i - \\frac{\\sigma_p}{N} \\right)^2$$\n",
    "\n",
    "subject to $\\sum w_i = 1$ and $w_i \\geq 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Risk Parity implementation ---\n",
    "\n",
    "def risk_contribution(w, cov_mat):\n",
    "    \"\"\"Compute the risk contribution of each asset.\"\"\"\n",
    "    port_vol = np.sqrt(np.dot(w.T, np.dot(cov_mat, w)))\n",
    "    # Marginal risk contribution\n",
    "    marginal = np.dot(cov_mat, w) / port_vol\n",
    "    # Risk contribution = weight * marginal contribution\n",
    "    rc = w * marginal\n",
    "    return rc\n",
    "\n",
    "\n",
    "def risk_parity_objective(w, cov_mat):\n",
    "    \"\"\"\n",
    "    Objective: minimize the sum of squared differences between\n",
    "    each asset's risk contribution and the target (equal) contribution.\n",
    "    \"\"\"\n",
    "    rc = risk_contribution(w, cov_mat)\n",
    "    target = np.sum(rc) / len(w)  # equal risk contribution target\n",
    "    return np.sum((rc - target) ** 2)\n",
    "\n",
    "\n",
    "# Optimize\n",
    "rp_constraints = [{\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0}]\n",
    "rp_bounds      = tuple((0.01, 1.0) for _ in range(n_assets))  # min 1% to avoid zeros\n",
    "rp_x0          = np.array([1.0 / n_assets] * n_assets)\n",
    "\n",
    "rp_result = minimize(\n",
    "    risk_parity_objective, rp_x0, args=(cov_values,),\n",
    "    method=\"SLSQP\", bounds=rp_bounds, constraints=rp_constraints,\n",
    "    options={\"ftol\": 1e-12, \"maxiter\": 1000},\n",
    ")\n",
    "\n",
    "w_risk_parity = rp_result.x\n",
    "ret_rp = float(np.dot(w_risk_parity, mean_returns.values))\n",
    "vol_rp = float(np.sqrt(np.dot(w_risk_parity.T, np.dot(cov_values, w_risk_parity))))\n",
    "sr_rp  = (ret_rp - RISK_FREE_RATE) / vol_rp\n",
    "\n",
    "# Verify equal risk contributions\n",
    "rc = risk_contribution(w_risk_parity, cov_values)\n",
    "rc_pct = rc / rc.sum() * 100\n",
    "\n",
    "print(\"=== Risk Parity Portfolio ===\")\n",
    "print(f\"  Optimization converged: {rp_result.success}\")\n",
    "print(f\"  Expected Return: {ret_rp:.2%}\")\n",
    "print(f\"  Volatility:      {vol_rp:.2%}\")\n",
    "print(f\"  Sharpe Ratio:    {sr_rp:.4f}\")\n",
    "print(f\"  Weights and Risk Contributions:\")\n",
    "for t, wt, rci in zip(tickers, w_risk_parity, rc_pct):\n",
    "    print(f\"    {t}: weight={wt:.4f} ({wt:.1%}), risk contrib={rci:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Risk contribution comparison: Risk Parity vs Mean-Variance ---\n",
    "rc_mv = risk_contribution(w_max_sharpe, cov_values)\n",
    "rc_mv_pct = rc_mv / rc_mv.sum() * 100\n",
    "\n",
    "rc_rp_pct = rc / rc.sum() * 100\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\"Max Sharpe: Risk Contributions\", \"Risk Parity: Risk Contributions\"),\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=tickers, y=rc_mv_pct,\n",
    "    text=[f\"{v:.1f}%\" for v in rc_mv_pct],\n",
    "    textposition=\"auto\", marker_color=\"indianred\",\n",
    "    name=\"Max Sharpe\",\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=tickers, y=rc_rp_pct,\n",
    "    text=[f\"{v:.1f}%\" for v in rc_rp_pct],\n",
    "    textposition=\"auto\", marker_color=\"seagreen\",\n",
    "    name=\"Risk Parity\",\n",
    "), row=1, col=2)\n",
    "\n",
    "# Add target line (20% each)\n",
    "for col in [1, 2]:\n",
    "    fig.add_hline(y=20, line_dash=\"dash\", line_color=\"black\",\n",
    "                  annotation_text=\"Target: 20%\", row=1, col=col)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Risk Contribution (%)\", range=[0, max(rc_mv_pct.max(), 40)], row=1, col=1)\n",
    "fig.update_yaxes(range=[0, max(rc_mv_pct.max(), 40)], row=1, col=2)\n",
    "fig.update_layout(height=400, template=\"plotly_white\", showlegend=False,\n",
    "                  title_text=\"Risk Contribution Comparison\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute risk-parity drawdown and Sortino for later comparison ---\n",
    "port_rp_returns = daily_returns.dot(w_risk_parity)\n",
    "ds_rp     = port_rp_returns[port_rp_returns < 0]\n",
    "ds_std_rp = float(ds_rp.std() * np.sqrt(TRADING_DAYS)) if len(ds_rp) > 0 else 0\n",
    "sortino_rp = (ret_rp - RISK_FREE_RATE) / ds_std_rp if ds_std_rp > 0 else 0\n",
    "\n",
    "cum_rp     = (1 + port_rp_returns).cumprod()\n",
    "dd_rp      = (cum_rp - cum_rp.cummax()) / cum_rp.cummax()\n",
    "max_dd_rp  = float(dd_rp.min())\n",
    "calmar_rp  = ret_rp / abs(max_dd_rp) if max_dd_rp != 0 else 0\n",
    "\n",
    "print(f\"Risk Parity - Sortino: {sortino_rp:.4f}, Max DD: {max_dd_rp:.2%}, Calmar: {calmar_rp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Strategy Comparison\n",
    "\n",
    "Compare all four strategies head-to-head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute min-variance drawdown and Sortino ---\n",
    "port_mv_returns = daily_returns.dot(w_min_var)\n",
    "ds_mv     = port_mv_returns[port_mv_returns < 0]\n",
    "ds_std_mv = float(ds_mv.std() * np.sqrt(TRADING_DAYS)) if len(ds_mv) > 0 else 0\n",
    "sortino_mv = (ret_min_var - RISK_FREE_RATE) / ds_std_mv if ds_std_mv > 0 else 0\n",
    "\n",
    "cum_mv     = (1 + port_mv_returns).cumprod()\n",
    "dd_mv      = (cum_mv - cum_mv.cummax()) / cum_mv.cummax()\n",
    "max_dd_mv  = float(dd_mv.min())\n",
    "calmar_mv  = ret_min_var / abs(max_dd_mv) if max_dd_mv != 0 else 0\n",
    "\n",
    "print(f\"Min Variance - Sortino: {sortino_mv:.4f}, Max DD: {max_dd_mv:.2%}, Calmar: {calmar_mv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Side-by-side comparison table ---\n",
    "comparison = pd.DataFrame({\n",
    "    \"Max Sharpe\": {\n",
    "        \"Ann. Return\":    f\"{ret_max_sharpe:.2%}\",\n",
    "        \"Ann. Volatility\": f\"{vol_max_sharpe:.2%}\",\n",
    "        \"Sharpe Ratio\":   f\"{sr_max_sharpe:.4f}\",\n",
    "        \"Sortino Ratio\":  f\"{sortino_ratio:.4f}\",\n",
    "        \"Max Drawdown\":   f\"{max_drawdown:.2%}\",\n",
    "        \"Calmar Ratio\":   f\"{calmar_ratio:.4f}\",\n",
    "    },\n",
    "    \"Min Variance\": {\n",
    "        \"Ann. Return\":    f\"{ret_min_var:.2%}\",\n",
    "        \"Ann. Volatility\": f\"{vol_min_var:.2%}\",\n",
    "        \"Sharpe Ratio\":   f\"{sr_min_var:.4f}\",\n",
    "        \"Sortino Ratio\":  f\"{sortino_mv:.4f}\",\n",
    "        \"Max Drawdown\":   f\"{max_dd_mv:.2%}\",\n",
    "        \"Calmar Ratio\":   f\"{calmar_mv:.4f}\",\n",
    "    },\n",
    "    \"Equal Weight\": {\n",
    "        \"Ann. Return\":    f\"{ret_equal:.2%}\",\n",
    "        \"Ann. Volatility\": f\"{vol_equal:.2%}\",\n",
    "        \"Sharpe Ratio\":   f\"{sr_equal:.4f}\",\n",
    "        \"Sortino Ratio\":  f\"{sortino_equal:.4f}\",\n",
    "        \"Max Drawdown\":   f\"{max_dd_equal:.2%}\",\n",
    "        \"Calmar Ratio\":   f\"{calmar_equal:.4f}\",\n",
    "    },\n",
    "    \"Risk Parity\": {\n",
    "        \"Ann. Return\":    f\"{ret_rp:.2%}\",\n",
    "        \"Ann. Volatility\": f\"{vol_rp:.2%}\",\n",
    "        \"Sharpe Ratio\":   f\"{sr_rp:.4f}\",\n",
    "        \"Sortino Ratio\":  f\"{sortino_rp:.4f}\",\n",
    "        \"Max Drawdown\":   f\"{max_dd_rp:.2%}\",\n",
    "        \"Calmar Ratio\":   f\"{calmar_rp:.4f}\",\n",
    "    },\n",
    "})\n",
    "\n",
    "print(\"Strategy Comparison\")\n",
    "print(\"=\" * 80)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Weight comparison across strategies ---\n",
    "weight_df = pd.DataFrame({\n",
    "    \"Max Sharpe\":  w_max_sharpe,\n",
    "    \"Min Variance\": w_min_var,\n",
    "    \"Equal Weight\": w_equal,\n",
    "    \"Risk Parity\":  w_risk_parity,\n",
    "}, index=tickers)\n",
    "\n",
    "print(\"Portfolio Weights\")\n",
    "print(\"=\" * 60)\n",
    "weight_display = weight_df.copy()\n",
    "for col in weight_display.columns:\n",
    "    weight_display[col] = weight_display[col].apply(lambda x: f\"{x:.1%}\")\n",
    "weight_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bar chart: Return, Volatility, Sharpe across strategies ---\n",
    "strategies = [\"Max Sharpe\", \"Min Variance\", \"Equal Weight\", \"Risk Parity\"]\n",
    "returns_list = [ret_max_sharpe, ret_min_var, ret_equal, ret_rp]\n",
    "vols_list    = [vol_max_sharpe, vol_min_var, vol_equal, vol_rp]\n",
    "sharpe_list  = [sr_max_sharpe, sr_min_var, sr_equal, sr_rp]\n",
    "colors       = [\"indianred\", \"steelblue\", \"goldenrod\", \"seagreen\"]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3,\n",
    "    subplot_titles=(\"Annualized Return\", \"Annualized Volatility\", \"Sharpe Ratio\"),\n",
    ")\n",
    "\n",
    "for i, (strat, ret, vol, sr, color) in enumerate(\n",
    "    zip(strategies, returns_list, vols_list, sharpe_list, colors)\n",
    "):\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[strat], y=[ret], name=strat,\n",
    "        marker_color=color, text=[f\"{ret:.1%}\"], textposition=\"auto\",\n",
    "        showlegend=(i == 0),  # only show legend once per strategy name\n",
    "        legendgroup=strat,\n",
    "    ), row=1, col=1)\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[strat], y=[vol], name=strat,\n",
    "        marker_color=color, text=[f\"{vol:.1%}\"], textposition=\"auto\",\n",
    "        showlegend=False, legendgroup=strat,\n",
    "    ), row=1, col=2)\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[strat], y=[sr], name=strat,\n",
    "        marker_color=color, text=[f\"{sr:.2f}\"], textposition=\"auto\",\n",
    "        showlegend=False, legendgroup=strat,\n",
    "    ), row=1, col=3)\n",
    "\n",
    "fig.update_yaxes(tickformat=\".0%\", row=1, col=1)\n",
    "fig.update_yaxes(tickformat=\".0%\", row=1, col=2)\n",
    "fig.update_layout(\n",
    "    height=450, template=\"plotly_white\",\n",
    "    title_text=\"Strategy Performance Comparison\",\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cumulative return comparison ---\n",
    "cum_max_sharpe = (1 + port_daily_returns).cumprod()\n",
    "cum_min_var    = (1 + port_mv_returns).cumprod()\n",
    "cum_equal_w    = (1 + port_equal_returns).cumprod()\n",
    "cum_rp_w       = (1 + port_rp_returns).cumprod()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for cum, name, color in [\n",
    "    (cum_max_sharpe, \"Max Sharpe\",   \"indianred\"),\n",
    "    (cum_min_var,    \"Min Variance\", \"steelblue\"),\n",
    "    (cum_equal_w,    \"Equal Weight\", \"goldenrod\"),\n",
    "    (cum_rp_w,       \"Risk Parity\",  \"seagreen\"),\n",
    "]:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cum.index, y=cum.values,\n",
    "        mode=\"lines\", name=name,\n",
    "        line=dict(color=color, width=2),\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative Return Comparison (All Strategies)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Cumulative Return (1 = start)\",\n",
    "    height=500,\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drawdown comparison ---\n",
    "fig = go.Figure()\n",
    "\n",
    "dd_max_sharpe = (cum_max_sharpe - cum_max_sharpe.cummax()) / cum_max_sharpe.cummax()\n",
    "\n",
    "for dd, name, color in [\n",
    "    (dd_max_sharpe, \"Max Sharpe\",   \"indianred\"),\n",
    "    (dd_mv,         \"Min Variance\", \"steelblue\"),\n",
    "    (dd_equal,      \"Equal Weight\", \"goldenrod\"),\n",
    "    (dd_rp,         \"Risk Parity\",  \"seagreen\"),\n",
    "]:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dd.index, y=dd.values,\n",
    "        mode=\"lines\", name=name,\n",
    "        line=dict(color=color, width=1.5),\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Drawdown Comparison (All Strategies)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Drawdown\",\n",
    "    yaxis_tickformat=\".0%\",\n",
    "    height=450,\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(yanchor=\"bottom\", y=0.01, xanchor=\"left\", x=0.01),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Next Steps / Extension Points\n",
    "\n",
    "This notebook provides a solid foundation for portfolio optimization research.\n",
    "Below are concrete ideas for extending the analysis further.\n",
    "\n",
    "### Black-Litterman Model\n",
    "Combine market equilibrium returns with subjective investor views to produce\n",
    "more stable expected return estimates. This reduces sensitivity to estimation\n",
    "error compared to raw historical means.\n",
    "\n",
    "### Hierarchical Risk Parity (HRP)\n",
    "Use hierarchical clustering on the correlation matrix to build a tree-based\n",
    "allocation. HRP avoids matrix inversion, making it more robust for\n",
    "ill-conditioned covariance matrices. See Lopez de Prado (2016).\n",
    "\n",
    "### Transaction Costs and Constraints\n",
    "- Add proportional transaction costs to the objective function.\n",
    "- Enforce sector exposure limits or minimum/maximum weight constraints.\n",
    "- Test turnover constraints for realistic rebalancing.\n",
    "\n",
    "### Real Market Data via yfinance\n",
    "Replace synthetic data with real prices:\n",
    "```python\n",
    "import yfinance as yf\n",
    "tickers = [\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"TSLA\"]\n",
    "prices = yf.download(tickers, start=\"2022-01-01\", end=\"2024-01-01\")[\"Close\"]\n",
    "```\n",
    "\n",
    "### Rebalancing Simulation\n",
    "Simulate monthly or quarterly rebalancing with walk-forward optimization.\n",
    "Track out-of-sample performance and compare strategies over rolling windows.\n",
    "\n",
    "### Factor Models\n",
    "- Decompose returns into Fama-French factors (market, size, value, momentum).\n",
    "- Use factor-based covariance estimation for better out-of-sample behavior.\n",
    "- Integrate with the project's `src.features.forensic` module for\n",
    "  fundamental-factor overlays.\n",
    "\n",
    "### Integration with Project Modules\n",
    "When running locally (not on Colab), this notebook can import directly from\n",
    "the project:\n",
    "```python\n",
    "from src.data.dummy_provider import DummyDataProvider\n",
    "from src.features.portfolio.optimizer import MeanVarianceOptimizer\n",
    "from src.core.types import PortfolioResult\n",
    "```\n",
    "The `OptimizerInterface` in `src.core.interfaces` provides a contract\n",
    "for adding new optimization strategies (e.g., `RiskParityOptimizer`,\n",
    "`BlackLittermanOptimizer`) that plug into the Streamlit app seamlessly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "vevn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 0,
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "nbformat": 4,
  "nbformat_minor": 4
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
